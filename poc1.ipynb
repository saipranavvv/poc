{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "619456e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# # Define your question-answer data as a list of dictionaries\n",
    "# qa_data = [\n",
    "#     {\"question\": \"What is your name?\", \"answer\": \"My name is Bard, a large language model.\"},\n",
    "#     {\"question\": \"How are you doing?\", \"answer\": \"I'm doing well, thank you for asking!\"},\n",
    "#     {\"question\": \"What can you do?\", \"answer\": \"I can answer your questions in an informative way. I am still under development, but I am learning new things every day.\"},\n",
    "#     {\"question\": \"What is PDC?\", \"answer\": \"It is Previous Day Composite. It combines previous day's transactions and forms a report\"},\n",
    "\n",
    "# ]\n",
    "\n",
    "# # Function to preprocess text data\n",
    "# def preprocess_text(text):\n",
    "#   # Convert to lowercase\n",
    "#   text = text.lower()\n",
    "#   # Remove punctuation\n",
    "#   text = \"\".join([char for char in text if char.isalnum() or char.isspace()])\n",
    "#   # Return cleaned text\n",
    "#   return text\n",
    "\n",
    "# # Preprocess questions and answers\n",
    "# processed_data = []\n",
    "# for item in qa_data:\n",
    "#   processed_data.append({\n",
    "#       \"question\": preprocess_text(item[\"question\"]),\n",
    "#       \"answer\": preprocess_text(item[\"answer\"]),\n",
    "#   })\n",
    "\n",
    "# # Extract questions and answers as separate lists\n",
    "# questions = [item[\"question\"] for item in processed_data]\n",
    "# answers = [item[\"answer\"] for item in processed_data]\n",
    "\n",
    "# # Create TF-IDF vectorizer\n",
    "# vectorizer = TfidfVectorizer()\n",
    "\n",
    "# # Fit the vectorizer on the combined questions and answers\n",
    "# vectorizer.fit(questions + answers)\n",
    "\n",
    "# # Function to find the most similar question based on TF-IDF cosine similarity\n",
    "# def find_similar_question(question):\n",
    "#   # Preprocess the user question\n",
    "#   processed_question = preprocess_text(question)\n",
    "#   # Transform the question into a TF-IDF vector\n",
    "#   question_vector = vectorizer.transform([processed_question])\n",
    "#   # Get TF-IDF vectors for all questions\n",
    "#   question_matrix = vectorizer.transform(questions)\n",
    "#   # Calculate cosine similarities between the user question and all questions\n",
    "#   similarities = question_matrix.dot(question_vector.T).toarray().squeeze()\n",
    "#   # Find the index of the most similar question\n",
    "#   most_similar_idx = similarities.argmax()\n",
    "#   return most_similar_idx\n",
    "\n",
    "# # Welcome message\n",
    "# print(\"Hi! I'm a simple Q&A bot. Ask me anything!\")\n",
    "\n",
    "# while True:\n",
    "#   # Get user question\n",
    "#   user_question = input(\"You: \").lower()\n",
    "\n",
    "#   # Find the most similar question based on TF-IDF similarity\n",
    "#   most_similar_idx = find_similar_question(user_question)\n",
    "\n",
    "#   # Retrieve the answer based on the similar question index\n",
    "#   answer = answers[most_similar_idx]\n",
    "\n",
    "#   # Print the answer\n",
    "#   print(\"Bard:\", answer)\n",
    "\n",
    "#   # Ask if user wants to continue\n",
    "#   user_continue = input(\"Do you want to ask another question? (yes/no) \").lower()\n",
    "#   if user_continue != \"yes\":\n",
    "#     break\n",
    "\n",
    "# print(\"Thanks for chatting with me! Bye!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "055cccc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('popular', quiet=True) #downloads packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b43a28d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('inputs.txt','r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw = raw.lower() #converts to lowercase to reduce repetition of  words like The and the or When and when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4c3e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "854e9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    robot_response=''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robot_response=robot_response+\"I think I need to read more about that...\"\n",
    "        return robot_response\n",
    "    else:\n",
    "        robot_response = robot_response+sent_tokens[idx]\n",
    "        return robot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4ffcffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = (\"namastey\",\"namaskaram\",\"hello\", \"hi\", \"whats up\",\"hey\")\n",
    "GREETING_RESPONSES = [\"namastey\",\"namaskaram\",\"hello\", \"hi\", \"whats up\",\"hey\"]\n",
    "def greeting(sentence):\n",
    " \n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c352854b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spongebot: Namaskaram I am Spongebot. I am an expert on history of India, you can ask me anything. Go ahead!\n",
      "hi\n",
      "Spongebot: hey\n",
      "what is cricket\n",
      "Spongebot: cricket is a bat-and-ball game that is played between two teams of eleven players on a field at the centre of which is a 22-yard (20-metre) pitch with a wicket at each end, each comprising two bails balanced on three stumps.\n",
      "how many members in one team in cricket\n",
      "Spongebot: cricket is a bat-and-ball game that is played between two teams of eleven players on a field at the centre of which is a 22-yard (20-metre) pitch with a wicket at each end, each comprising two bails balanced on three stumps.\n",
      "what is the length of the pitch?\n",
      "Spongebot: cricket is a bat-and-ball game that is played between two teams of eleven players on a field at the centre of which is a 22-yard (20-metre) pitch with a wicket at each end, each comprising two bails balanced on three stumps.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpongebot: Namaskaram I am Spongebot. I am an expert on history of India, you can ask me anything. Go ahead!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(flag\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m----> 6\u001b[0m     user_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m()\n\u001b[1;32m      7\u001b[0m     user_response\u001b[38;5;241m=\u001b[39muser_response\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(user_response\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbye!!\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1267\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "flag=True\n",
    "print(\"Spongebot: Namaskaram I am Spongebot. I am an expert on history of India, you can ask me anything. Go ahead!\")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye!!'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"\"\"Spongebot: Anytime\"\"\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"Spongebot: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"Spongebot: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"Spongebot: take care..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8542a099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5bc5af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93522672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c538a975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2208d951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
